{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the necessary libraries\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 as cv\n",
    "import librosa\n",
    "import requests\n",
    "import os\n",
    "import zipfile\n",
    "import tarfile\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from datetime import datetime\n",
    "from glob import glob\n",
    "import shutil\n",
    "# import wget\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_data():\n",
    "    datasets = {\n",
    "    'cv_corpus_url' : 'https://storage.googleapis.com/common-voice-prod-prod-datasets/cv-corpus-15.0-delta-2023-09-08/cv-corpus-15.0-delta-2023-09-08-en.tar.gz?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=gke-prod%40moz-fx-common-voice-prod.iam.gserviceaccount.com%2F20231028%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20231028T130917Z&X-Goog-Expires=43200&X-Goog-SignedHeaders=host&X-Goog-Signature=9130e79b07e55f29c6aaac409e5a827618721404298a15c07d009547952a1eea168e5d5d8b020d84aa0ef90dd7e03064894bff5629525f06e30ea45fba39d7bbd0eff945b89ef6e83f522d478018045e68e03c43c23e733f00fc2c1ea9cdcfd818c8ae2daeb7a8efc3b8babb096980b0a5f7c93a745264e8d06c02b3ccaacd156324b4b8feff865bbd62887d73869bccc50849755b27bbe9db06ae7832150ba15c091d7f423edbabbdf6793814898bb2a68721a019817e9be9af18fd882b14b6570c5f0b2cee9f64ccc9bfb20bd5de42c44f7357fc1f6269f13cf74b448a86fc5991fedee04c7f8748fd6a6bfd2bc7a4a01bf6379a73da55f5a4c00ff1dbe000',\n",
    "    'LJ_Speech_url' : 'https://data.keithito.com/data/speech/LJSpeech-1.1.tar.bz2'\n",
    "    }\n",
    "\n",
    "    cv_corpus_path = os.path.join(os.getcwd(),'cv-corpus-15.0-delta-2023-09-08-en.tar.gz')\n",
    "    LJ_speech_path = os.path.join(os.getcwd(),'LJSpeech-1.1.tar.bz2')\n",
    "\n",
    "    for data in datasets.keys():\n",
    "        print(f'Downloading {data}')\n",
    "        print(datasets[data])\n",
    "        # requests.get(datasets[data])\n",
    "\n",
    "        if data == 'cv_corpus_url':\n",
    "          response = requests.get(datasets[data])\n",
    "          with open(cv_corpus_path, 'wb') as f:\n",
    "            f.write(response.content)\n",
    "            print('Done downloading CVcorpus')\n",
    "            try:\n",
    "              print('extracting cvcorpus')\n",
    "              with tarfile.open(cv_corpus_path,'r:gz') as z:\n",
    "                  z.extractall()\n",
    "                  print('Done extracting CVcorpus')\n",
    "            except:\n",
    "                print(\"Unable to complete CVcorpus request\")\n",
    "\n",
    "            os.remove(cv_corpus_path)\n",
    "\n",
    "        elif data == 'LJ_Speech_url':\n",
    "            files = requests.get(datasets[data])\n",
    "            with open(LJ_speech_path, 'wb') as f:\n",
    "              f.write(files.content)\n",
    "            print('Done downloading CVcorpus')\n",
    "            with tarfile.open(LJ_speech_path, \"r:bz2\") as f:\n",
    "              f.extractall()\n",
    "              print('Done downloading LJ_Speech')\n",
    "            try:\n",
    "                with zipfile.ZipFile(LJ_speech_path) as z:\n",
    "                    z.extractall(os.path.join(os.getcwd(),'LJSpeech'))\n",
    "                    print('Done extracting LJ_Speech')\n",
    "            except:\n",
    "                print(\"Unable to complete LJSpeech request\")\n",
    "\n",
    "            os.remove(LJ_speech_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_cv_corpus():\n",
    "  cv_corpus_audio_file_paths = os.path.join(os.getcwd(),'cv-corpus-15.0-delta-2023-09-08','en','clips')\n",
    "  cv_corpus_audio_files = os.listdir(cv_corpus_audio_file_paths)\n",
    "  for files in cv_corpus_audio_files:\n",
    "    src_path = os.path.join(os.getcwd(),'cv-corpus-15.0-delta-2023-09-08','en','clips',files)\n",
    "    dst_path = os.path.join(os.getcwd(),'cv-corpus',files)\n",
    "    shutil.move(src_path,dst_path)\n",
    "  os.remove( os.path.join(os.getcwd(),'cv-corpus-15.0-delta-2023-09-08'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_LJ_Speech():\n",
    "  LJSpeech_audio_file_path = os.path.join(os.getcwd(),'cv-corpus-15.0-delta-2023-09-08','en','clips')\n",
    "  cv_corpus_audio_files = os.listdir(LJSpeech_audio_file_path)\n",
    "  for files in cv_corpus_audio_files:\n",
    "    src_path = os.path.join(os.getcwd(),'cv-corpus-15.0-delta-2023-09-08','en','clips',files)\n",
    "    dst_path = os.path.join(os.getcwd(),'cv-corpus',files)\n",
    "    shutil.move(src_path,dst_path)\n",
    "  os.remove( os.path.join(os.getcwd(),'cv-corpus-15.0-delta-2023-09-08'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#specify the paths for your audio files\n",
    "class Paths:\n",
    "    LJSpeech: str = os.path.join(os.getcwd(),'LJSpeech')\n",
    "    CVcorpus: str = os.path.join(os.getcwd(),'CVcorpus')\n",
    "    Spectrum_images_train: str = os.path.join(os.getcwd(),'Spectrum_Images','train')\n",
    "    Spectrum_images_train: str = os.path.join(os.getcwd(),'Spectrum_Images','valid')\n",
    "    CVcorpus_Spectrum_train_images: str = os.path.join(os.getcwd(),'Spectrum_Images','train','CVcorpus')\n",
    "    LJSpeech_Spectrum_train_images: str = os.path.join(os.getcwd(),'Spectrum_Images','train','LJSpeech')\n",
    "    Spectrum_images_valid: str = os.path.join(os.getcwd(),'Spectrum_Images_valid')\n",
    "    CVcorpus_Spectrum_valid_images: str = os.path.join(os.getcwd(),'Spectrum_Images','valid','CVcorpus')\n",
    "    LJSpeech_Spectrum_valid_images: str = os.path.join(os.getcwd(),'Spectrum_Images','valid','LJSpeech')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create folders for the different audio files\n",
    "os.makedirs(Paths.CVcorpus_Spectrum_train_images)\n",
    "os.makedirs(Paths.LJSpeech_Spectrum_train_images)\n",
    "os.makedirs(Paths.CVcorpus_Spectrum_valid_images)\n",
    "os.makedirs(Paths.LJSpeech_Spectrum_valid_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#function to process audio and generate the spectrum images\n",
    "\n",
    "class Prep_data():\n",
    "    def __init__(self):\n",
    "       pass\n",
    "\n",
    "    def process_audio(self,audio_path,save_location,filename):\n",
    "        audio, fs = librosa.load(audio_path)\n",
    "        D = librosa.amplitude_to_db(librosa.stft(audio), ref=np.max)\n",
    "        # Save the spectrogram\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.axis('off')\n",
    "        librosa.display.specshow(D, sr=fs, x_axis='time', y_axis='linear',cmap='viridis')\n",
    "        plt.savefig(save_location+'\\\\'+filename+'.jpg', dpi=300, bbox_inches='tight', pad_inches=0,transparent=True)\n",
    "\n",
    "    def crop_image(image):\n",
    "        imag = np.array(image)\n",
    "        # print(imag)\n",
    "        mask = np.zeros(image.shape,dtype=np.uint8)\n",
    "        cv.rectangle(mask,(100,50),(710,585),(255,255,255),-1)\n",
    "        image = np.bitwise_and(imag,mask)\n",
    "        x, y, w, h = 100,50,610,535\n",
    "\n",
    "        # Crop the image using the bounding rectangle coordinates\n",
    "        cropped_image = image[y:y + h, x:x + w]\n",
    "        image =np.array(image)\n",
    "        return cropped_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function \n",
    "def crop_image(image):\n",
    "    imag = np.array(image)\n",
    "    # print(imag)\n",
    "    mask = np.zeros(image.shape,dtype=np.uint8)\n",
    "    cv.rectangle(mask,(100,50),(710,585),(255,255,255),-1)\n",
    "    image = np.bitwise_and(imag,mask)\n",
    "    x, y, w, h = 100,50,610,535\n",
    "\n",
    "    # Crop the image using the bounding rectangle coordinates\n",
    "    cropped_image = image[y:y + h, x:x + w]\n",
    "    image =np.array(image)\n",
    "    return cropped_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#process the audio files to generate the spectrum images\n",
    "for audios in os.listdir(Paths.CVcorpus[:300]):\n",
    "    Prep_data.process_audio(Paths.CVcorpus+f'\\\\{audios}',Paths.CVcorpus_Spectrum_train_images,audios)\n",
    "\n",
    "for audios in os.listdir(Paths.CVcorpus[300:]):\n",
    "    Prep_data.process_audio(Paths.CVcorpus+f'\\\\{audios}',Paths.CVcorpus_Spectrum_valid_images,audios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#process the audio files to generate the spectrum images\n",
    "for audios in os.listdir(Paths.LJSpeech[:300]):\n",
    "    Prep_data.process_audio(Paths.LJSpeech+f'\\\\{audios}',Paths.LJSpeech_Spectrum_train_images,audios)\n",
    "\n",
    "for audios in os.listdir(Paths.LJSpeech[300:]):\n",
    "    Prep_data.process_audio(Paths.LJSpeech+f'\\\\{audios}',Paths.LJSpeech_Spectrum_valid_images,audios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1/255,fill_mode='nearest',horizontal_flip=True,zoom_range=0.5,vertical_flip=True)\n",
    "valid_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_datagen.flow_from_directory(Paths.Spectrum_images_train,target_size=(300,300),class_mode='binary')\n",
    "valid_imges = valid_datagen.flow_from_directory(Paths.Spectrum_images_valid,target_size=(300,300),class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.applications.vgg16.VGG16(include_top=False,weights='imagenet',input_shape=(300,300,3)))\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(512,activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(32,activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='sgd',loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a TensorBoard callback\n",
    "log_dir = \"logs/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_images,valid_imges,epochs=10, callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('final_model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
